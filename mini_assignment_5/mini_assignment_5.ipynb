{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mini Assignment 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0) Running model with predefined settings**\n",
    "\n",
    "Before we start tweaking anything, let's look at how the orignal model performs to get a feel for the baseline. Below are the parameters that the model contained originally:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "def simpleCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3),activation='linear',kernel_initializer='he_uniform',\n",
    "                     input_shape=(240, 240, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(keras.layers.noise.GaussianNoise(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(Dropout(0.25)) # Avoid over-fitting  \n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "CNN=simpleCNN()\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print (model.summary())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_189 (Conv2D)          (None, 238, 238, 16)      160       \n",
    "_________________________________________________________________\n",
    "batch_normalization_189 (Bat (None, 238, 238, 16)      64        \n",
    "_________________________________________________________________\n",
    "re_lu_1 (ReLU)               (None, 238, 238, 16)      0         \n",
    "_________________________________________________________________\n",
    "max_pooling2d_9 (MaxPooling2 (None, 119, 119, 16)      0         \n",
    "_________________________________________________________________\n",
    "conv2d_190 (Conv2D)          (None, 117, 117, 32)      4640      \n",
    "_________________________________________________________________\n",
    "batch_normalization_190 (Bat (None, 117, 117, 32)      128       \n",
    "_________________________________________________________________\n",
    "re_lu_2 (ReLU)               (None, 117, 117, 32)      0         \n",
    "_________________________________________________________________\n",
    "max_pooling2d_10 (MaxPooling (None, 58, 58, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_191 (Conv2D)          (None, 56, 56, 64)        18496     \n",
    "_________________________________________________________________\n",
    "batch_normalization_191 (Bat (None, 56, 56, 64)        256       \n",
    "_________________________________________________________________\n",
    "re_lu_3 (ReLU)               (None, 56, 56, 64)        0         \n",
    "_________________________________________________________________\n",
    "max_pooling2d_11 (MaxPooling (None, 28, 28, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_192 (Conv2D)          (None, 26, 26, 128)       73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_192 (Bat (None, 26, 26, 128)       512       \n",
    "_________________________________________________________________\n",
    "re_lu_4 (ReLU)               (None, 26, 26, 128)       0         \n",
    "_________________________________________________________________\n",
    "max_pooling2d_12 (MaxPooling (None, 5, 5, 128)         0         \n",
    "_________________________________________________________________\n",
    "gaussian_noise_1 (GaussianNo (None, 5, 5, 128)         0         \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 3200)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 128)               409728    \n",
    "_________________________________________________________________\n",
    "re_lu_5 (ReLU)               (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 3)                 387       \n",
    "_________________________________________________________________\n",
    "activation_189 (Activation)  (None, 3)                 0         \n",
    "=================================================================\n",
    "Total params: 508,227\n",
    "Trainable params: 507,747\n",
    "Non-trainable params: 480\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "epochs=2\n",
    "class_weight= {0 : 1., 1:3., 2:5.}\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(TrainSequence,steps_per_epoch=len(TrainSequence) ,validation_data = ValidationSequence,validation_steps = len(ValidationSequence) \n",
    "                              ,epochs=epochs,workers=1, max_queue_size=4,verbose=1,callbacks=callbacks, shuffle=False,class_weight=class_weight)\n",
    "                              `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/2\n",
    "325/325 [==============================] - 28s 87ms/step - loss: 2.5337 - acc: 0.4851 - val_loss: 0.9281 - val_acc: 0.6319\n",
    "Epoch 2/2\n",
    "325/325 [==============================] - 17s 53ms/step - loss: 1.9505 - acc: 0.5870 - val_loss: 0.8314 - val_acc: 0.6667\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the summary of the model on the validation and test sets:**\n",
    "\n",
    "### **Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.8926    0.6821    0.7733       195\n",
    "   1p19q preserved     0.4900    0.6806    0.5698        72\n",
    "   1p19q codeleted     0.2564    0.4762    0.3333        21\n",
    "\n",
    "       avg / total     0.7456    0.6667    0.6903       288\n",
    "\n",
    "Summary\n",
    "Precision:  0.7455729794068721\n",
    "Recall:  0.6666666666666666\n",
    "F1 Score:  0.6903060400516796\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.7921    0.7477    0.7692       107\n",
    "   1p19q preserved     0.6022    0.6829    0.6400        82\n",
    "   1p19q codeleted     0.3077    0.2581    0.2807        31\n",
    "\n",
    "       avg / total     0.6530    0.6545    0.6522       220\n",
    "\n",
    "Precision:  0.6530330948727627\n",
    "Recall:  0.6545454545454545\n",
    "F1 Score:  0.6522247576984419\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1) Add additional layers to the network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will add another convolutional layer to the model with 8 kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "def simpleCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3, 3),activation='linear',kernel_initializer='he_uniform', # new layer\n",
    "                     input_shape=(240, 240, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(keras.layers.noise.GaussianNoise(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(Dropout(0.25)) # Avoid over-fitting  \n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "CNN=simpleCNN()\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "model=CNN\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(TrainSequence,steps_per_epoch=len(TrainSequence) ,validation_data = ValidationSequence,validation_steps = len(ValidationSequence) \n",
    "                              ,epochs=epochs,workers=1, max_queue_size=4,verbose=1,callbacks=callbacks, shuffle=False,class_weight=class_weight)\n",
    "                              `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/2\n",
    "325/325 [==============================] - 18s 56ms/step - loss: 2.7859 - acc: 0.4462 - val_loss: 0.9390 - val_acc: 0.6215\n",
    "Epoch 2/2\n",
    "325/325 [==============================] - 17s 53ms/step - loss: 2.1443 - acc: 0.5265 - val_loss: 0.8816 - val_acc: 0.6458\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the summary of the model on the validation and test sets:**\n",
    "\n",
    "### **Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.8926    0.6821    0.7733       195\n",
    "   1p19q preserved     0.4900    0.6806    0.5698        72\n",
    "   1p19q codeleted     0.2564    0.4762    0.3333        21\n",
    "\n",
    "       avg / total     0.7456    0.6667    0.6903       288\n",
    "\n",
    "Summary\n",
    "Precision:  0.7455729794068721\n",
    "Recall:  0.6666666666666666\n",
    "F1 Score:  0.6903060400516796\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.8193    0.6355    0.7158       107\n",
    "   1p19q preserved     0.5273    0.7073    0.6042        82\n",
    "   1p19q codeleted     0.4074    0.3548    0.3793        31\n",
    "\n",
    "       avg / total     0.6524    0.6227    0.6268       220\n",
    "\n",
    "Precision:  0.6524029266745586\n",
    "Recall:  0.6227272727272727\n",
    "F1 Score:  0.626771641093329\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2) Change the number of neurons in those layers**\n",
    "\n",
    "Here, we will double all the neurons in each layer in the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "def simpleCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),activation='linear',kernel_initializer='he_uniform',\n",
    "                     input_shape=(240, 240, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(keras.layers.noise.GaussianNoise(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(Dropout(0.25)) # Avoid over-fitting  \n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "CNN=simpleCNN()\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "model=CNN\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(TrainSequence,steps_per_epoch=len(TrainSequence) ,validation_data = ValidationSequence,validation_steps = len(ValidationSequence) \n",
    "                              ,epochs=epochs,workers=1, max_queue_size=4,verbose=1,callbacks=callbacks, shuffle=False,class_weight=class_weight)\n",
    "                              `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/2\n",
    "325/325 [==============================] - 18s 56ms/step - loss: 1.4918 - acc: 0.6747 - val_loss: 0.7700 - val_acc: 0.6528\n",
    "Epoch 2/2\n",
    "325/325 [==============================] - 17s 54ms/step - loss: 1.2506 - acc: 0.7349 - val_loss: 0.7380 - val_acc: 0.6562\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the summary of the model on the validation and test sets:**\n",
    "\n",
    "### **Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.9485    0.6615    0.7795       195\n",
    "   1p19q preserved     0.4752    0.6667    0.5549        72\n",
    "   1p19q codeleted     0.2353    0.5714    0.3333        21\n",
    "\n",
    "       avg / total     0.7782    0.6562    0.6908       288\n",
    "\n",
    "Summary\n",
    "Precision:  0.7782021998155698\n",
    "Recall:  0.65625\n",
    "F1 Score:  0.6907906768380591\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.8966    0.7290    0.8041       107\n",
    "   1p19q preserved     0.6630    0.7439    0.7011        82\n",
    "   1p19q codeleted     0.4634    0.6129    0.5278        31\n",
    "\n",
    "       avg / total     0.7485    0.7182    0.7268       220\n",
    "\n",
    "Precision:  0.7484838789031205\n",
    "Recall:  0.7181818181818181\n",
    "F1 Score:  0.7268027322639836\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3) Change some of the hyper-parameters in the network configuration like dropout or learning rate, etc.**\n",
    "\n",
    "When we added another conv. layer with 8 nodes, this may have led to overfitting seeing as the validation precision was 10% higher than the test set. To correct this, we will increase the dropout of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "def simpleCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (3, 3),activation='linear',kernel_initializer='he_uniform', # new layer\n",
    "                     input_shape=(240, 240, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3),activation='linear',kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(keras.layers.noise.GaussianNoise(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(ReLU())   # add an advanced activation\n",
    "    model.add(Dropout(0.35)) # Avoid over-fitting  \n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "CNN=simpleCNN()\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/2\n",
    "325/325 [==============================] - 18s 56ms/step - loss: 1.4918 - acc: 0.6747 - val_loss: 0.7700 - val_acc: 0.6528\n",
    "Epoch 2/2\n",
    "325/325 [==============================] - 17s 54ms/step - loss: 1.2506 - acc: 0.7349 - val_loss: 0.7380 - val_acc: 0.6562\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the summary of the model on the validation and test sets:**\n",
    "\n",
    "### **Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.9301    0.6821    0.7870       195\n",
    "   1p19q preserved     0.4348    0.6944    0.5348        72\n",
    "   1p19q codeleted     0.1667    0.2381    0.1961        21\n",
    "\n",
    "       avg / total     0.7506    0.6528    0.6808       288\n",
    "\n",
    "Summary\n",
    "Precision:  0.7505832784365394\n",
    "Recall:  0.6527777777777778\n",
    "F1 Score:  0.6808397892956717\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                    precision    recall  f1-score   support\n",
    "\n",
    "No Hyper Intensity     0.8571    0.6729    0.7539       107\n",
    "   1p19q preserved     0.5688    0.7561    0.6492        82\n",
    "   1p19q codeleted     0.3333    0.2903    0.3103        31\n",
    "\n",
    "       avg / total     0.6759    0.6500    0.6524       220\n",
    "\n",
    "Precision:  0.6758628221930973\n",
    "Recall:  0.65\n",
    "F1 Score:  0.6523929491703458\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Please describe how you experimented with the code and if you achieved better results, or not.  Please submit your results here (text descriptions, screenshots, or link notebook all are fine submission types).**\n",
    "\n",
    "1) I tried to improve the performance of my model where I added a layer which seemed to be overfitting. I increased the dropout from .25 to .35, however this only marginally improved the model by increasing test set precision by 2%. \n",
    "\n",
    "2) I doubled all the nodes in each layer, which increased test set precision to 75%, which was 10% better than the original model. This model was also 10 seconds faster in epoch 1 than the original model, which does not make sense. Perhaps there was something going on behind the scenes where something had to initialize, because one would expect that more nodes = longer compiling time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
